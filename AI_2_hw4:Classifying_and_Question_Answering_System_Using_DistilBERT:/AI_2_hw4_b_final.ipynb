{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Τεχνητή Νοημοσύνη 2**\n",
        "#**Εργασία 4b**\n",
        "Στέφανος Μπακλαβάς 1115201700093"
      ],
      "metadata": {
        "id": "badIx2CllH-P"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "crEJM2gAiTlq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b098cb3-1ec8-4ed6-fc9c-6871855da69a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (4.6.3)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "\n",
        "!pip install beautifulsoup4\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import figure\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn import datasets, linear_model\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn import preprocessing\n",
        "from sklearn.metrics import f1_score\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mIiubvQllf3i",
        "outputId": "b7693669-d5bc-49f8-b63e-0f520eae57e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.7/dist-packages (1.18.4)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.17.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets) (3.8.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.4.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.18.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.11.2)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.21.5)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.12.2)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.63.0)\n",
            "Requirement already satisfied: pyarrow!=4.0.0,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n",
            "Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2022.2.0)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.10.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.6.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.25.11)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.47)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.11.6)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.7.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.3.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (21.4.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (6.0.2)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (0.13.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.2.0)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.0.12)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.7.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (0.11.1+cu111)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.21.5)\n",
            "Requirement already satisfied: torch==1.10.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.10.0+cu111)\n",
            "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (7.1.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.10.0->torchvision) (3.10.0.2)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.96)\n"
          ]
        }
      ],
      "source": [
        "! pip install datasets transformers\n",
        "!pip install torchvision \n",
        "!pip install sentencepiece\n",
        "\n",
        "import torch\n",
        "import torchvision\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Tazxh4PZ9i1",
        "outputId": "4695f0c2-0cc6-48e3-c1d6-1715e7eafb51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "git-lfs is already the newest version (2.3.4-1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 39 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "!apt install git-lfs"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Utilizing Gpu if available\n"
      ],
      "metadata": {
        "id": "sxV0eSE1lTnt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tUOka69eJhki",
        "outputId": "67be58f3-9805-4a70-ea40-a95ba5228ae9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla K80\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "datasets = load_dataset(\"squad_v2\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "d74edb052a1e4f58a67954efdee26920",
            "2d243fc7e83942f8a80e033cc9fb86b3",
            "4ae981a39da44ed7822c55fff1946cfb",
            "dea28c3ee4cd4a8db0220ddafde312ba",
            "dee12296697c4b678d7db4293d06d5b1",
            "8f91ba9c42184cd5886b27466ff50ff7",
            "bdc0b8611ab5406d995bea847b670013",
            "7cf4f670867c4282b179adf9c0301a23",
            "2dcad60d10974964ac8a37f992eaf5cb",
            "6d2cbd145dc84597ac7aff5aaf2f5e00",
            "86d60749a6294fea9a01e60399f0af2b"
          ]
        },
        "id": "MUyDat1h9WsB",
        "outputId": "82b39b85-278a-41be-f275-22609895ed19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Reusing dataset squad_v2 (/root/.cache/huggingface/datasets/squad_v2/squad_v2/2.0.0/09187c73c1b837c95d9a249cd97c2c3f1cebada06efe667b4427714b27639b1d)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d74edb052a1e4f58a67954efdee26920"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "datasets\n",
        "train_data = datasets['train']\n",
        "validation_data = datasets['validation']"
      ],
      "metadata": {
        "id": "lI4wIJsv91i8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data[1]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "daF8q6ntAnE3",
        "outputId": "fb2b3d7f-b485-4ebb-ba5e-d0e05ebcbdaa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'answers': {'answer_start': [207], 'text': ['singing and dancing']},\n",
              " 'context': 'Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny\\'s Child. Managed by her father, Mathew Knowles, the group became one of the world\\'s best-selling girl groups of all time. Their hiatus saw the release of Beyoncé\\'s debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles \"Crazy in Love\" and \"Baby Boy\".',\n",
              " 'id': '56be85543aeaaa14008c9065',\n",
              " 'question': 'What areas did Beyonce compete in when she was growing up?',\n",
              " 'title': 'Beyoncé'}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2eBVymt9II1",
        "outputId": "4e54d4c4-630a-4b7d-8c1e-a81514ed8559"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "130319"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Θέτουμε το μέγιστο μήκος για κάθε sequence καθώς και το μέγιστο μήκος που θα έχει η επικάλυψη δύο κειμένων. Αν ένα κείμενο έχει μήκος μεγαλύτερο από 384 τότε σπάει σε μικρότερα τα οποία επικαλύπτονται"
      ],
      "metadata": {
        "id": "yXRuYA0MlaGb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = 384 # The maximum length of a feature (question and context)\n",
        "doc_stride = 128 # The authorized overlap between two part of the context when splitting it is needed."
      ],
      "metadata": {
        "id": "01d-IcAwfccJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer,AdamW,BertForQuestionAnswering\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")"
      ],
      "metadata": {
        "id": "j5goJuyQ2n4V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Παρακάτω για κάθε ερώτηση που υπάρχιει για κάθε κείμενο βρίσκουμε το τέλος και την αρχή της tokenized απάντησης μέσα στο κείμενο , αφού η θέση της μπορεί να αλλάξει μετά το tokenization. Η παρακάτω συνάρτηση αποτελεί έναν από τους δύο standard τρόπους με τους οποίους γίνεται αυτό."
      ],
      "metadata": {
        "id": "en03Tb_Elz-0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_train_features(examples):\n",
        "    # Some of the questions have lots of whitespace on the left, which is not useful and will make the\n",
        "    # truncation of the context fail (the tokenized question will take a lots of space). So we remove that\n",
        "    # left whitespace\n",
        "    examples[\"question\"] = [q.lstrip() for q in examples[\"question\"]]\n",
        "\n",
        "    # Tokenize our examples with truncation and padding, but keep the overflows using a stride. This results\n",
        "    # in one example possible giving several features when a context is long, each of those features having a\n",
        "    # context that overlaps a bit the context of the previous feature.\n",
        "    tokenized_examples = tokenizer(\n",
        "        examples[\"question\"] ,\n",
        "        examples[\"context\" ],\n",
        "        truncation=\"only_second\",\n",
        "        max_length=max_length,\n",
        "        stride=doc_stride,\n",
        "        return_overflowing_tokens=True,\n",
        "        return_offsets_mapping=True,\n",
        "        padding=\"max_length\",\n",
        "    )\n",
        "\n",
        "    # Since one example might give us several features if it has a long context, we need a map from a feature to\n",
        "    # its corresponding example. This key gives us just that.\n",
        "    sample_mapping = tokenized_examples.pop(\"overflow_to_sample_mapping\")\n",
        "    # The offset mappings will give us a map from token to character position in the original context. This will\n",
        "    # help us compute the start_positions and end_positions.\n",
        "    offset_mapping = tokenized_examples.pop(\"offset_mapping\")\n",
        "\n",
        "    # Let's label those examples!\n",
        "    tokenized_examples[\"start_positions\"] = []\n",
        "    tokenized_examples[\"end_positions\"] = []\n",
        "\n",
        "    for i, offsets in enumerate(offset_mapping):\n",
        "        # We will label impossible answers with the index of the CLS token.\n",
        "        input_ids = tokenized_examples[\"input_ids\"][i]\n",
        "        cls_index = input_ids.index(tokenizer.cls_token_id)\n",
        "\n",
        "        # Grab the sequence corresponding to that example (to know what is the context and what is the question).\n",
        "        sequence_ids = tokenized_examples.sequence_ids(i)\n",
        "\n",
        "        # One example can give several spans, this is the index of the example containing this span of text.\n",
        "        sample_index = sample_mapping[i]\n",
        "        answers = examples[\"answers\"][sample_index]\n",
        "        # If no answers are given, set the cls_index as answer.\n",
        "        if len(answers[\"answer_start\"]) == 0:\n",
        "            tokenized_examples[\"start_positions\"].append(cls_index)\n",
        "            tokenized_examples[\"end_positions\"].append(cls_index)\n",
        "        else:\n",
        "            # Start/end character index of the answer in the text.\n",
        "            start_char = answers[\"answer_start\"][0]\n",
        "            end_char = start_char + len(answers[\"text\"][0])\n",
        "\n",
        "            # Start token index of the current span in the text.\n",
        "            token_start_index = 0\n",
        "            while sequence_ids[token_start_index] != 1:\n",
        "                token_start_index += 1\n",
        "\n",
        "            # End token index of the current span in the text.\n",
        "            token_end_index = len(input_ids) - 1\n",
        "            while sequence_ids[token_end_index] != 1:\n",
        "                token_end_index -= 1\n",
        "\n",
        "            # Detect if the answer is out of the span (in which case this feature is labeled with the CLS index).\n",
        "            if not (offsets[token_start_index][0] <= start_char and offsets[token_end_index][1] >= end_char):\n",
        "                tokenized_examples[\"start_positions\"].append(cls_index)\n",
        "                tokenized_examples[\"end_positions\"].append(cls_index)\n",
        "            else:\n",
        "                # Otherwise move the token_start_index and token_end_index to the two ends of the answer.\n",
        "                # Note: we could go after the last offset if the answer is the last word (edge case).\n",
        "                while token_start_index < len(offsets) and offsets[token_start_index][0] <= start_char:\n",
        "                    token_start_index += 1\n",
        "                tokenized_examples[\"start_positions\"].append(token_start_index - 1)\n",
        "                while offsets[token_end_index][1] >= end_char:\n",
        "                    token_end_index -= 1\n",
        "                tokenized_examples[\"end_positions\"].append(token_end_index + 1)\n",
        "\n",
        "    return tokenized_examples\n",
        "\n",
        "    #isws na metatrepsw auta se listes kai na tis epistrefw"
      ],
      "metadata": {
        "id": "spn6MBj02CNt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Εφαρμογή της συνάρτησησς prepare_train_features για κάθε ερώτηση του dataset"
      ],
      "metadata": {
        "id": "8jer7FXpmaP6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_datasets = datasets.map(prepare_train_features, batched=True, remove_columns=datasets[\"train\"].column_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "c3946f1512b84c3b9184500ca6d90058",
            "52c28161972542c28adfff84f6591270",
            "3c4424264241462cb74d05a6d57bb775",
            "d0959ec030f84bb2ae2dab372a34a95a",
            "e7792b4e52464ff5b9025b2145f2ece3",
            "a918a0033ea1407db605981eeeda07e6",
            "7ee0e8037a3b4fdab9f91c32f39f8a90",
            "033675fdaea84e68a0803f4bddcad46e",
            "4d417c923b9b4fc6b87fd89650c90da6",
            "895200ac2a3f4191888cb8106fb116ef",
            "f31da892ed32401f8410cf92cae1a935"
          ]
        },
        "id": "mhj-35XV2cvh",
        "outputId": "8417fdd8-f87d-4868-bd9a-bff01f9342ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/squad_v2/squad_v2/2.0.0/09187c73c1b837c95d9a249cd97c2c3f1cebada06efe667b4427714b27639b1d/cache-2ec3ec6f1a16a4bc.arrow\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/12 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c3946f1512b84c3b9184500ca6d90058"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Μεταρτροπή των δεδομένων του dataset ποου χρειαζόμαστε σε tensors και σπάσιμο σε train και validation sets"
      ],
      "metadata": {
        "id": "p5eE9zwsmhsa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_input_ids =  torch.tensor(tokenized_datasets[\"train\"][\"input_ids\"])\n",
        "validation_input_ids = torch.tensor(tokenized_datasets[\"validation\"][\"input_ids\"])\n",
        "\n",
        "train_attention_mask =  torch.tensor(tokenized_datasets[\"train\"][\"attention_mask\"])\n",
        "validation_attention_mask = torch.tensor(tokenized_datasets[\"validation\"][\"attention_mask\"])\n",
        "\n",
        "train_start_positions =  torch.tensor(tokenized_datasets[\"train\"][\"start_positions\"])\n",
        "validation_start_positions = torch.tensor(tokenized_datasets[\"validation\"][\"start_positions\"])\n",
        "\n",
        "train_end_positions =  torch.tensor(tokenized_datasets[\"train\"][\"end_positions\"])\n",
        "validation_end_positions = torch.tensor(tokenized_datasets[\"validation\"][\"end_positions\"])\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "xqRor3BHSbu1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Δημιουργία των τελικών μορφών του train και validation sets στην μορφή που τα χρειάζεται το μοντέλο"
      ],
      "metadata": {
        "id": "JmpB0MSemt1c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_tokenized_dataset = list(zip(*(train_input_ids,train_attention_mask,train_start_positions,train_end_positions)))\n",
        "validation_tokenized_dataset = list(zip(*(validation_input_ids,validation_attention_mask,validation_start_positions,validation_end_positions)))\n",
        "\n",
        "train_tokenized_dataset[2][3]\n",
        "\n",
        "#train_tokenized_dataset = train_tokenized_dataset[:4]\n",
        "#validation_tokenized_dataset = validation_tokenized_dataset[:4]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VZMdePVGMRS2",
        "outputId": "91b037da-3464-40ff-e407-8c5eff2fc1c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(143)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_datasets[\"train\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RKvwT-S8KlzW",
        "outputId": "7fcb3850-6cec-4d5f-af4a-ebce1e592f85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['input_ids', 'token_type_ids', 'attention_mask', 'start_positions', 'end_positions'],\n",
              "    num_rows: 131754\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Χρησιμοποιείται ως model το distilbert-base-uncased του DistilBertForQuestionAnswering , ενώ το learning rate με τα καλύτερα αποτελέσματα ήταν το 5e-5. Πρέπει να σημειωθεί ότι και τα τρια learning rates που χρησιμοποιήθηκαν είχαν σχεδόν ίδιο αποτέλεσμα.Συγκεκριμένα έγιναν δοκιμές με lr = 2e-5, lr = 3e-5 και lr = 5e-5. Δυστυχώς λόγω περιορισμών χρήσης στην GPU δεν κατάφερα να τρέξω κάποιο μοντέλο για πάνω από μία epoch οπότε τα αποτελέσματα του κάθε learning rate στο readme είναι για μια epoch\n"
      ],
      "metadata": {
        "id": "wVZcOkQ_m8P9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "from transformers import AdamW\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
        "# linear classification layer on top. \n",
        "from transformers import DistilBertForQuestionAnswering\n",
        "model = DistilBertForQuestionAnswering.from_pretrained(\"distilbert-base-uncased\")\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(),  lr = 5e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )\n",
        "\n",
        "\n",
        "#optimizer = AdamW(model.parameters(),\n",
        " #                 lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "  #                eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "   #             )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "model.cuda()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xSE7Cgp-FuHr",
        "outputId": "b37a1f58-cbd6-4908-c813-f50478796363"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForQuestionAnswering: ['vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DistilBertForQuestionAnswering(\n",
              "  (distilbert): DistilBertModel(\n",
              "    (embeddings): Embeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (transformer): Transformer(\n",
              "      (layer): ModuleList(\n",
              "        (0): TransformerBlock(\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (activation): GELUActivation()\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (1): TransformerBlock(\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (activation): GELUActivation()\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (2): TransformerBlock(\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (activation): GELUActivation()\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (3): TransformerBlock(\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (activation): GELUActivation()\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (4): TransformerBlock(\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (activation): GELUActivation()\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (5): TransformerBlock(\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (activation): GELUActivation()\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (qa_outputs): Linear(in_features=768, out_features=2, bias=True)\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Προετοιμασία των dataloaders .Το batch size που χρησιμοποιήθηκε και στις τρεις δοκιμές είναι το 24 καθώς αυτό παρουσιάζεται και στο σχετικό paper"
      ],
      "metadata": {
        "id": "byau_1Onnat6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZrLgqEfNEwJQ"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "dataloader_train = DataLoader(\n",
        "            train_tokenized_dataset,  # The training samples.\n",
        "            shuffle = True, \n",
        "            batch_size = 24, # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
        "dataloader_validation = DataLoader(\n",
        "            validation_tokenized_dataset, # The validation samples.\n",
        "            shuffle = True, \n",
        "            batch_size = 24, # Evaluate with this batch size.\n",
        "\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Συναρτήσεις για τον υπολογισμό του f1 score των batches"
      ],
      "metadata": {
        "id": "izHwlgaNnpnQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cal_average(num):\n",
        "    sum_num = 0.0\n",
        "    for t in num:\n",
        "        sum_num = sum_num + t           \n",
        "\n",
        "    avg = sum_num / len(num)\n",
        "    return avg\n",
        "\n",
        "\n",
        "#f1 score of one example\n",
        "def compute_f1(real_start,real_end, pred_start,pred_end):\n",
        "  #gold_toks = get_tokens(real_pos)\n",
        "  #pred_toks = get_tokens(pred_pos)\n",
        "  if real_start < pred_start:\n",
        "    start = pred_start\n",
        "  else:\n",
        "    start = real_start\n",
        "  if real_end > pred_end:\n",
        "    end = pred_end\n",
        "  else:\n",
        "    end = real_end     \n",
        "  #common = collections.Counter(gold_toks) & collections.Counter(pred_toks)\n",
        "  \n",
        "  num_same = end - start\n",
        "  pred_same = pred_end - pred_start\n",
        "  real_same = real_end - real_start\n",
        "  \n",
        "  if num_same < 0:\n",
        "    return 0 \n",
        "  if real_same == 0 or pred_same == 0:\n",
        "    # If either is no-answer, then F1 is 1 if they agree, 0 otherwise\n",
        "    if real_start == pred_start:\n",
        "      return 1\n",
        "    else:\n",
        "      return 0  \n",
        "    #return int(gold_toks == pred_toks)\n",
        "  if num_same == 0:\n",
        "    return 0\n",
        "\n",
        "  num_same  = num_same+1\n",
        "  pred_same = pred_same +1\n",
        "  real_Same = real_same +1\n",
        "\n",
        "  precision = 1.0 * num_same / pred_same\n",
        "  recall = 1.0 * num_same / real_same\n",
        "  f1 = (2 * precision * recall) / (precision + recall)\n",
        "  return f1\n",
        "\n",
        "#f1 score of epoch\n",
        "#here each arguiment is a list\n",
        "def f1_of_epoch(real_start,real_end, pred_start,pred_end):\n",
        "\n",
        "  f1_scores = []\n",
        "  length = len(real_start)\n",
        "  for i in range(length):\n",
        "    f1 = compute_f1(real_start[i],real_end[i],pred_start[i],pred_end[i])\n",
        "    f1_scores.append(f1)\n",
        "    #print(\"added f1 = \",f1)\n",
        "\n",
        "  f1_final = cal_average(f1_scores)\n",
        "  \n",
        "  return f1_final\n"
      ],
      "metadata": {
        "id": "E7fX6NwJPI1V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tqdm\n",
        "import tqdm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3gqCkxRGo9Ro",
        "outputId": "c95daf0e-0b75-4d0a-e3d3-02ac231d0263"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.63.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training and validation of model "
      ],
      "metadata": {
        "id": "eQabrqR1pcWp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2NVPdkX8VItv",
        "outputId": "143503ed-929c-4dd5-f912-7411921baf04"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training batch =  0\n",
            "training batch =  100\n",
            "training batch =  200\n",
            "training batch =  300\n",
            "training batch =  400\n",
            "training batch =  500\n",
            "training batch =  600\n",
            "training batch =  700\n",
            "training batch =  800\n",
            "training batch =  900\n",
            "training batch =  1000\n",
            "training batch =  1100\n",
            "training batch =  1200\n",
            "training batch =  1300\n",
            "training batch =  1400\n",
            "training batch =  1500\n",
            "training batch =  1600\n",
            "training batch =  1700\n",
            "training batch =  1800\n",
            "training batch =  1900\n",
            "training batch =  2000\n",
            "training batch =  2100\n",
            "training batch =  2200\n",
            "training batch =  2300\n",
            "training batch =  2400\n",
            "training batch =  2500\n",
            "training batch =  2600\n",
            "training batch =  2700\n",
            "training batch =  2800\n",
            "training batch =  2900\n",
            "training batch =  3000\n",
            "training batch =  3100\n",
            "training batch =  3200\n",
            "training batch =  3300\n",
            "training batch =  3400\n",
            "training batch =  3500\n",
            "training batch =  3600\n",
            "training batch =  3700\n",
            "training batch =  3800\n",
            "training batch =  3900\n",
            "training batch =  4000\n",
            "training batch =  4100\n",
            "training batch =  4200\n",
            "training batch =  4300\n",
            "training batch =  4400\n",
            "training batch =  4500\n",
            "training batch =  4600\n",
            "training batch =  4700\n",
            "training batch =  4800\n",
            "training batch =  4900\n",
            "training batch =  5000\n",
            "training batch =  5100\n",
            "training batch =  5200\n",
            "training batch =  5300\n",
            "training batch =  5400\n",
            "validation batch =  0\n",
            "validation batch =  100\n",
            "validation batch =  200\n",
            "validation batch =  300\n",
            "validation batch =  400\n",
            "validation batch =  500\n",
            "\n",
            " LAST 30 PREDICTIONS \n",
            "\n",
            "real start =  [27, 34, 0, 46, 0, 116, 0, 0, 34, 0, 48, 0, 74, 0, 0, 0, 155, 0, 94, 39, 132, 115, 0, 117, 162, 0, 53, 0, 177, 0]\n",
            "real end =  [27, 42, 0, 46, 0, 121, 0, 0, 34, 0, 48, 0, 74, 0, 0, 0, 157, 0, 94, 42, 150, 115, 0, 125, 162, 0, 59, 0, 192, 0]\n",
            "predicted start =  [25, 52, 0, 46, 0, 116, 267, 103, 0, 152, 48, 0, 74, 99, 23, 37, 155, 143, 94, 39, 136, 115, 20, 119, 161, 65, 53, 0, 163, 184]\n",
            "predicted end =  [27, 42, 0, 46, 0, 117, 276, 37, 0, 153, 49, 0, 75, 99, 0, 39, 157, 143, 94, 41, 142, 115, 21, 120, 162, 65, 59, 0, 166, 0]\n",
            "\n",
            "\n",
            "f1_score =  0.6594578834746686\n",
            "training batch =  0\n",
            "training batch =  100\n",
            "training batch =  200\n",
            "training batch =  300\n",
            "training batch =  400\n",
            "training batch =  500\n",
            "training batch =  600\n",
            "training batch =  700\n",
            "training batch =  800\n",
            "training batch =  900\n",
            "training batch =  1000\n",
            "training batch =  1100\n",
            "training batch =  1200\n",
            "training batch =  1300\n",
            "training batch =  1400\n",
            "training batch =  1500\n",
            "training batch =  1600\n"
          ]
        }
      ],
      "source": [
        "from numpy.core.fromnumeric import argmax\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "\n",
        "from itertools import cycle\n",
        "\n",
        "from sklearn import svm, datasets\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from scipy import interp\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "from scipy.special import softmax\n",
        "import random \n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set the seed value .\n",
        "seed_val = 5\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "\n",
        "def Average(lst):\n",
        "    return sum(lst) / len(lst)\n",
        "\n",
        "train_loss = []\n",
        "validation_loss = []\n",
        "epochs = []\n",
        "fpr = dict()\n",
        "tpr = dict()\n",
        "roc_auc = dict()\n",
        "best_epoch_preds = []\n",
        "best_epoch_y_values = []\n",
        "prev_max_presicion = 0\n",
        "\n",
        "for epoch in range(4):\n",
        "  \n",
        "  batch_losses_train = []\n",
        "  batch_losses_validation = []\n",
        "\n",
        "  start_preds = []\n",
        "  end_preds = []\n",
        "\n",
        "  start_values = []\n",
        "  end_values = []\n",
        "\n",
        "\n",
        "  model.train()\n",
        "  \n",
        "  counter1 = 0\n",
        "\n",
        "\n",
        "  for batch in dataloader_train:\n",
        "\n",
        "\n",
        "      if counter1 % 100 == 0:\n",
        "        print(\"training batch = \",counter1)\n",
        "      counter1 = counter1+1\n",
        "\n",
        "    \n",
        "      b_input_ids = batch[0].to(device)\n",
        "      b_input_mask = batch[1].to(device)\n",
        "      start_positions = batch[2].to(device)\n",
        "      end_positions = batch[3].to(device)\n",
        "\n",
        "\n",
        "      model.zero_grad()        \n",
        "\n",
        "      output = model(b_input_ids,  \n",
        "                             attention_mask=b_input_mask, \n",
        "                             start_positions = start_positions,end_positions = end_positions)\n",
        "\n",
        "\n",
        "\n",
        "      loss = output.loss\n",
        "      start_logits = output.start_logits\n",
        "      end_logits = output.end_logits\n",
        "      batch_losses_train.append(loss.item())\n",
        "     \n",
        "      loss.backward()\n",
        "\n",
        "      optimizer.step()\n",
        "\n",
        "\n",
        "  train_loss.append(Average(batch_losses_train))\n",
        "  batch_losses_train.clear\n",
        "\n",
        "  model.eval()\n",
        "\n",
        "  counter2 = 0\n",
        "\n",
        "  torch.save(model.state_dict(),'/content/drive/MyDrive/Colab Notebooks/model3_AI_2_HW4.pt')\n",
        "\n",
        "  for batch in dataloader_validation:\n",
        "\n",
        "   \n",
        "      if counter2 % 100 == 0:\n",
        "        print(\"validation batch = \",counter2)\n",
        "      counter2 = counter2 +1\n",
        "  \n",
        "      b_input_ids = batch[0].to(device)\n",
        "      b_input_mask = batch[1].to(device)\n",
        "      start_positions = batch[2].to(device)\n",
        "      end_positions = batch[3].to(device)\n",
        "\n",
        "\n",
        "      with torch.no_grad():\n",
        "\n",
        "        output = model(b_input_ids,  \n",
        "                              attention_mask=b_input_mask, \n",
        "                              start_positions = start_positions,end_positions = end_positions)\n",
        "\n",
        "\n",
        "      loss = output.loss\n",
        "      start_logits = output.start_logits\n",
        "      end_logits = output.end_logits\n",
        "      batch_losses_validation.append(loss.item())\n",
        "     \n",
        "      start_positions = start_positions.to('cpu').numpy()\n",
        "      end_positions = end_positions.to('cpu').numpy()\n",
        "\n",
        "      start_logits = start_logits.detach().cpu().numpy()\n",
        "      end_logits = end_logits.detach().cpu().numpy()\n",
        "\n",
        "\n",
        "      start_logits = softmax(start_logits)\n",
        "      end_logits = softmax(end_logits)\n",
        "      for pred in start_logits:\n",
        "        start_preds.append(argmax(pred))\n",
        "      for v_pred in end_logits:\n",
        "        end_preds.append(argmax(v_pred))\n",
        "      for val in start_positions:\n",
        "        start_values.append(val) \n",
        "      for val in end_positions:\n",
        "        end_values.append(val)   \n",
        "\n",
        "      batch_losses_validation.append(loss.item())\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  validation_loss.append(Average(batch_losses_validation))\n",
        "  batch_losses_validation.clear\n",
        "\n",
        "  #############################################################################################################\n",
        "  #calculating scores\n",
        "  epochs.append(epoch)\n",
        "  validation_loss.append(Average(batch_losses_validation))\n",
        " \n",
        "  print(\"\\n LAST 30 PREDICTIONS \\n\")\n",
        "  print(\"real start = \",start_values[-30:])\n",
        "  print(\"real end = \",end_values[-30:])\n",
        "  print(\"predicted start = \",start_preds[-30:])\n",
        "  print(\"predicted end = \",end_preds[-30:])\n",
        "\n",
        "  #print(\"start_values length = \",len(start_values))\n",
        "  f1_score = f1_of_epoch(start_values,end_values,start_preds,end_preds)\n",
        "  print(\"\\n\\nf1_score = \",f1_score)\n",
        "\n",
        "\n",
        "  start_preds.clear()\n",
        "  end_preds.clear()\n",
        "\n",
        "  start_values.clear()\n",
        "  end_values.clear()\n",
        "\n",
        "\n",
        "\n",
        "  batch_losses_validation.clear\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "54BmoyH9zhNn"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "AI_2_hw4_b_final.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d74edb052a1e4f58a67954efdee26920": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2d243fc7e83942f8a80e033cc9fb86b3",
              "IPY_MODEL_4ae981a39da44ed7822c55fff1946cfb",
              "IPY_MODEL_dea28c3ee4cd4a8db0220ddafde312ba"
            ],
            "layout": "IPY_MODEL_dee12296697c4b678d7db4293d06d5b1"
          }
        },
        "2d243fc7e83942f8a80e033cc9fb86b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8f91ba9c42184cd5886b27466ff50ff7",
            "placeholder": "​",
            "style": "IPY_MODEL_bdc0b8611ab5406d995bea847b670013",
            "value": "100%"
          }
        },
        "4ae981a39da44ed7822c55fff1946cfb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7cf4f670867c4282b179adf9c0301a23",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2dcad60d10974964ac8a37f992eaf5cb",
            "value": 2
          }
        },
        "dea28c3ee4cd4a8db0220ddafde312ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6d2cbd145dc84597ac7aff5aaf2f5e00",
            "placeholder": "​",
            "style": "IPY_MODEL_86d60749a6294fea9a01e60399f0af2b",
            "value": " 2/2 [00:00&lt;00:00, 19.59it/s]"
          }
        },
        "dee12296697c4b678d7db4293d06d5b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f91ba9c42184cd5886b27466ff50ff7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bdc0b8611ab5406d995bea847b670013": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7cf4f670867c4282b179adf9c0301a23": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2dcad60d10974964ac8a37f992eaf5cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6d2cbd145dc84597ac7aff5aaf2f5e00": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86d60749a6294fea9a01e60399f0af2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c3946f1512b84c3b9184500ca6d90058": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_52c28161972542c28adfff84f6591270",
              "IPY_MODEL_3c4424264241462cb74d05a6d57bb775",
              "IPY_MODEL_d0959ec030f84bb2ae2dab372a34a95a"
            ],
            "layout": "IPY_MODEL_e7792b4e52464ff5b9025b2145f2ece3"
          }
        },
        "52c28161972542c28adfff84f6591270": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a918a0033ea1407db605981eeeda07e6",
            "placeholder": "​",
            "style": "IPY_MODEL_7ee0e8037a3b4fdab9f91c32f39f8a90",
            "value": "100%"
          }
        },
        "3c4424264241462cb74d05a6d57bb775": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_033675fdaea84e68a0803f4bddcad46e",
            "max": 12,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4d417c923b9b4fc6b87fd89650c90da6",
            "value": 12
          }
        },
        "d0959ec030f84bb2ae2dab372a34a95a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_895200ac2a3f4191888cb8106fb116ef",
            "placeholder": "​",
            "style": "IPY_MODEL_f31da892ed32401f8410cf92cae1a935",
            "value": " 12/12 [00:08&lt;00:00,  1.49ba/s]"
          }
        },
        "e7792b4e52464ff5b9025b2145f2ece3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a918a0033ea1407db605981eeeda07e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ee0e8037a3b4fdab9f91c32f39f8a90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "033675fdaea84e68a0803f4bddcad46e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d417c923b9b4fc6b87fd89650c90da6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "895200ac2a3f4191888cb8106fb116ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f31da892ed32401f8410cf92cae1a935": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}